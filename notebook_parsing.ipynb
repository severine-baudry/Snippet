{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from git import Repo\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_output_marking(notebook, output_mark):\n",
    "    for cell_idx,cell in enumerate(notebook[\"cells\"]):\n",
    "        if cell[\"cell_type\"] == \"code\":\n",
    "            for output in cell[\"outputs\"]:\n",
    "                if \"text\" in output :\n",
    "                    found = False\n",
    "                    for line in output[\"text\"]:\n",
    "                        if line.find(output_mark)!= -1:\n",
    "                            #print(\"MARK FOUND !\", cell_idx)\n",
    "                            found = True\n",
    "                    if found :\n",
    "                        return output[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize_output(output_text):\n",
    "    '''\n",
    "    split notebook into tokens \n",
    "    separators : whitespace  ','  ':'\n",
    "    '''\n",
    "    res =[]\n",
    "    for line in output_text :\n",
    "    #    a = re.split(' |\\n|:', line)\n",
    "        #a = re.split('\\s|:|,', line)\n",
    "        # split outputs on whitespace, : and ,\n",
    "        split_line = re.split('[\\s|:|,]+', line)\n",
    "        # remove empty tokens\n",
    "        split_line = [ a for a in split_line if len(a)]\n",
    "        #print(split_line)\n",
    "        res.append(split_line)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def parse_nn_performances(split_lines):\n",
    "    res = OrderedDict( )\n",
    "    for line in split_lines:\n",
    "        if 'VALID' in line :\n",
    "            res.setdefault('VALID', OrderedDict())\n",
    "            perf_type = 'VALID'\n",
    "        elif 'TEST' in line :\n",
    "            res.setdefault('TEST', OrderedDict())\n",
    "            perf_type = 'TEST'            \n",
    "        else :\n",
    "            perf_type = 'TRAIN'\n",
    "            res.setdefault('TRAIN', OrderedDict())\n",
    "        if not 'Epoch' in line :\n",
    "            print(\"not a result line\")\n",
    "            continue\n",
    "        d_index = {}\n",
    "        l_names = [ 'loss', 'accuracy', 'Epoch']\n",
    "        d_type = {'loss':float, 'accuracy':float, 'Epoch':int }\n",
    "        d_val = {}\n",
    "        for name in l_names :\n",
    "            d_index[name] = line.index(name)\n",
    "        if d_index['loss'] == -1 and d_index['accuracy'] == -1 :\n",
    "            print(\"error : not a performance line\", line)\n",
    "        else :\n",
    "            try :\n",
    "                for name, index in d_index.items():\n",
    "                    if index > -1 :\n",
    "                        d_val[name] = d_type[name](line[index+1])\n",
    "            except ValueError :\n",
    "                print(\"error conversion\", name, index, line)\n",
    "            else :\n",
    "                epoch = d_val[\"Epoch\"]\n",
    "                del(d_val['Epoch'])\n",
    "                for name, perf in d_val.items() :\n",
    "                    res[perf_type].setdefault(name, OrderedDict() )\n",
    "                    res[perf_type][name][ epoch] = perf\n",
    "    return res\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_performance(results, metric):\n",
    "    plt.figure()\n",
    "    plt.plot( list( res[\"TRAIN\"][metric].keys()), list(res[\"TRAIN\"][metric].values() ) , label =\"TRAIN\")\n",
    "    plt.plot( list( res[\"VALID\"][metric].keys()), list(res[\"VALID\"][metric].values() ) , label =\"VALID\")\n",
    "    plt.legend()\n",
    "    plt.title(metric)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_perf_(notebook_f, l_markers = [\"Begin Training\", \"TEST\" ] ):\n",
    "        notebook = json.load(notebook_f)\n",
    "        res = OrderedDict()\n",
    "        for output_mark in  l_markers :\n",
    "            # find output cell beginning with output_mark\n",
    "            output_text = find_output_marking(notebook, output_mark)\n",
    "            if output_text :\n",
    "                # tokenize output cell\n",
    "                split_lines = tokenize_output(output_text)\n",
    "                # extract results from cell\n",
    "                dict_result = parse_nn_performances(split_lines)\n",
    "                res.update(dict_result)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_notebook_train_valid(notebook_name, l_markers = [\"Begin Training\", \"TEST\" ]  ):\n",
    "    if type(notebook_name) is str :\n",
    "        with open(notebook_name) as f :\n",
    "            return extract_perf_(f, l_markers)\n",
    "    else :\n",
    "        return extract_perf_(notebook_name)\n",
    "# In[43]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_notebook_parsing():\n",
    "    results = extract_notebook_train_valid(\"/home/severine/MOOCS/UDACITY/DEEP_LEARNING/TP/P2_dog_classification/Transfer_Learning_Solution_copy.ipynb\")\n",
    "    plot_performance(results, \"loss\")                 \n",
    "    plot_performance(results, \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metric_phase(l_results, phase, metric):\n",
    "    df_result = pd.DataFrame()\n",
    "    for result in result :\n",
    "        sha = result[\"sha\"][:5]        \n",
    "        dres = result[phase][metric]\n",
    "        df_current = pd.DataFrame.from_dict(dres, orient = 'index')\n",
    "        df_result = pd.concat([df_current], axis = 1)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-d\", dest = \"directory\", required = True)\n",
    "    parser.add_argument(\"-nb\", dest = \"notebook\", required = True)\n",
    "    parser.add_argument(\"-o\", dest = \"output\", required = True)\n",
    "    l_args = parser.parse_args()\n",
    "    \n",
    "    print(l_args.notebook)\n",
    "    print(l_args.output)\n",
    "    \n",
    "    repo = Repo(l_args.directory)\n",
    "    head = repo.head.reference\n",
    "    l_results = []\n",
    "    # iterate on the previous commits\n",
    "    for commit in list( repo.iter_commits( ) ) :\n",
    "        sha = commit.hexsha\n",
    "        msg = commit.message\n",
    "        dat = commit.authored_date\n",
    "        strdate = time.strftime(\"%d/%m/%Y %H:%M\", time.gmtime(dat))\n",
    "        # dat = commit.commited_date\n",
    "        # files in the commit\n",
    "        for tr in commit.tree:\n",
    "            # load the notebook\n",
    "            if tr.name == l_args.notebook:\n",
    "                print(sha[:7], strdate, msg )\n",
    "                results = extract_notebook_train_valid(tr.data_stream)\n",
    "                res_dict = OrderedDict( [(\"sha\", sha), (\"date\", strdate), (\"msg\", msg), (\"res\", results) ] )\n",
    "                l_results.append(res_dict)\n",
    "    with open(l_args.output, \"w\") as fs :\n",
    "        json.dump(l_results, fs, indent = 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple of execuation**\n",
    "\n",
    "python notebook_parsing.py  -d ../P2_dog_classification/ -nb Transfer_Learning_Solution_copy.ipynb  -o dogs_transfer_learning.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
